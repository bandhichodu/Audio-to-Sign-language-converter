{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzBdcBP1VorcHVyMVHTTmO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TqSKlN_2lbAv","executionInfo":{"status":"ok","timestamp":1722275105272,"user_tz":-330,"elapsed":171948,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"9aced7b6-02e9-4dbb-f4c4-2e120dfc2f72"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai-whisper\n","  Downloading openai-whisper-20231117.tar.gz (798 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/798.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/798.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.4)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n","Collecting tiktoken (from openai-whisper)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.15.4)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper, ffmpeg\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=3ddbd373bc4190ff55cf3193ab784b19d43f581852eab07f5b4aed4cc1e92fb9\n","  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=a122a6f7e42523f7ee2593f0bd2434ab67f320ae7483a0d05a530123fde8bc09\n","  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n","Successfully built openai-whisper ffmpeg\n","Installing collected packages: pydub, ffmpeg, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","Successfully installed ffmpeg-1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 pydub-0.25.1 tiktoken-0.7.0\n","Mounted at /content/drive\n","Word to Video Mapping (Sample): {'1': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/1.mp4', '0': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/0.mp4', 'his': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/His.mp4', 'from': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/From.mp4', 'gold': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Gold.mp4', 'college': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/College.mp4', 'here': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Here.mp4', '5': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/5.mp4', 'also': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Also.mp4', 'best': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Best.mp4'}\n","Letter to Video Mapping (Sample): {'e': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/E.mp4', 'c': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/C.mp4', 'b': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/B.mp4', 'f': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/F.mp4', 'd': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/D.mp4', 'g': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/G.mp4', 'a': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/A.mp4', 'h': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/H.mp4', 's': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/S.mp4', 't': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/T.mp4'}\n"]},{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 139MiB/s]\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-890bdd13-6a97-45c2-80a1-f69cd67438d9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-890bdd13-6a97-45c2-80a1-f69cd67438d9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Audio can u help me.mp3 to Audio can u help me.mp3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"stream","name":"stdout","text":["Transcribed Text:  can you help me?\n","No video found for word: you. Spelling out the word.\n","Moviepy - Building video l_output_video.mp4.\n","Moviepy - Writing video l_output_video.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":["t:  31%|███       | 70/226 [00:02<00:04, 32.50it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Y.mp4, 2764800 bytes wanted but 0 bytes read,at frame 40/41, at time 1.67/1.67 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n"]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready l_output_video.mp4\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f56b7950-bcd6-4e7d-a37d-4da48417b20a\", \"l_output_video.mp4\", 256763)"]},"metadata":{}}],"source":["4# Step 1: Install Necessary Libraries\n","\n","!pip install openai-whisper pydub ffmpeg moviepy\n","\n","# Step 2: Mount Google Drive (if needed)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 3: Create Mappings for Words and Letters\n","\n","import os\n","\n","# Path to the dataset in Google Drive\n","dataset_path = '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS'  # Update this path if needed\n","\n","# Create mappings for words and letters\n","word_to_video = {}\n","letter_to_video = {}\n","\n","# Track words and letters that couldn't be mapped\n","missing_words = set()\n","\n","for root, dirs, files in os.walk(dataset_path):\n","    for file in files:\n","        if file.endswith('.mp4'):\n","            file_path = os.path.join(root, file)\n","            file_name = os.path.splitext(file)[0].lower()  # Ensure the key is lowercase\n","\n","            # Assume file names for words are like 'hello.mp4' and for letters 'a.mp4', 'b.mp4', etc.\n","            if len(file_name) == 1 and file_name.isalpha():  # It's a letter\n","                letter_to_video[file_name] = file_path\n","            else:  # It's a word\n","                word_to_video[file_name] = file_path\n","\n","# Display mappings for verification\n","print(\"Word to Video Mapping (Sample):\", dict(list(word_to_video.items())[:10]))\n","print(\"Letter to Video Mapping (Sample):\", dict(list(letter_to_video.items())[:10]))\n","\n","# Function to check for missing words after generating the video\n","import string\n","\n","def clean_text(text):\n","    # Remove punctuation and convert text to lowercase\n","    return text.translate(str.maketrans('', '', string.punctuation)).lower()\n","\n","def check_missing_words(transcribed_text, word_to_video, letter_to_video):\n","    cleaned_text = clean_text(transcribed_text)\n","    words = cleaned_text.split()\n","    for word in words:\n","        if word not in word_to_video:\n","            if all(letter in letter_to_video for letter in word if letter.isalpha()):\n","                # If all letters in the word are available in letter_to_video\n","                missing_words.add(word)\n","            else:\n","                # If the word is not fully mappable\n","                missing_words.add(word)\n","    if missing_words:\n","        print(\"Missing Words (No video found):\", missing_words)\n","\n","# Step 4: Transcribe Audio to Text using Whisper\n","\n","from google.colab import files\n","import whisper\n","from pydub import AudioSegment\n","import os\n","\n","# Load the pre-trained Whisper model\n","model = whisper.load_model(\"base\")\n","\n","def convert_to_wav(input_file):\n","    # Extract the file extension\n","    file_extension = os.path.splitext(input_file)[1].lower()\n","    if file_extension in ['.mp3', '.mp4']:\n","        audio = AudioSegment.from_file(input_file)\n","        wav_file = \"converted_audio.wav\"\n","        audio.export(wav_file, format=\"wav\")\n","        return wav_file\n","    elif file_extension == '.wav':\n","        return input_file\n","    else:\n","        raise ValueError(f\"Unsupported file format: {file_extension}\")\n","\n","def audio_to_text(audio_file_path):\n","    # Convert the audio file to WAV if necessary\n","    wav_file = convert_to_wav(audio_file_path)\n","    # Transcribe the audio file\n","    result = model.transcribe(wav_file)\n","    # Convert text to lowercase\n","    lowercase_text = result[\"text\"].lower()\n","    return lowercase_text\n","\n","# Upload the audio file\n","uploaded = files.upload()\n","\n","# Get the name of the uploaded file\n","audio_file_path = list(uploaded.keys())[0]\n","transcribed_text = audio_to_text(audio_file_path)\n","print(\"Transcribed Text:\", transcribed_text)\n","\n","# Step 5: Generate the ISL Video\n","\n","from moviepy.editor import VideoFileClip, concatenate_videoclips\n","\n","def generate_isl_video(input_text, word_to_video, letter_to_video):\n","    video_clips = []\n","    words = clean_text(input_text).split()\n","\n","    for word in words:\n","        if word in word_to_video:\n","            video_path = word_to_video[word]\n","            clip = VideoFileClip(video_path)\n","            video_clips.append(clip)\n","        else:\n","            print(f\"No video found for word: {word}. Spelling out the word.\")\n","            for letter in word:\n","                if letter in letter_to_video:\n","                    video_path = letter_to_video[letter]\n","                    clip = VideoFileClip(video_path)\n","                    video_clips.append(clip)\n","                else:\n","                    print(f\"No video found for letter: {letter}\")\n","\n","    if video_clips:\n","        final_video = concatenate_videoclips(video_clips, method=\"compose\")\n","        final_video.write_videofile(\"l_output_video.mp4\")\n","    else:\n","        print(\"No valid ISL videos found for the given text.\")\n","\n","# Generate the ISL video using the transcribed text\n","generate_isl_video(transcribed_text, word_to_video, letter_to_video)\n","\n","from google.colab import files\n","\n","# Download the video\n","files.download(\"l_output_video.mp4\")\n"]},{"cell_type":"code","source":["# Step 1: Install Necessary Libraries\n","\n","!pip install openai-whisper pydub ffmpeg moviepy"],"metadata":{"id":"J2EWdnCWm7Cx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722536426153,"user_tz":-330,"elapsed":95899,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"e278ef4d-1837-46e8-a067-95a7714f70ae"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai-whisper\n","  Downloading openai-whisper-20231117.tar.gz (798 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.4)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n","Collecting tiktoken (from openai-whisper)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.15.4)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper)\n","  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: openai-whisper, ffmpeg\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=f2fbd0b469aaf087f54597e8c060a15603c435d5ee94ac690e91e9f60262634e\n","  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=be23507f76a87578dd993c173043d6d640d8fa0134dd462381a9bf0db63338cd\n","  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n","Successfully built openai-whisper ffmpeg\n","Installing collected packages: pydub, ffmpeg, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","Successfully installed ffmpeg-1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 pydub-0.25.1 tiktoken-0.7.0\n"]}]},{"cell_type":"code","source":["# Step 2: Mount Google Drive (if needed)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTpoIBFAm8O3","executionInfo":{"status":"ok","timestamp":1722536460752,"user_tz":-330,"elapsed":21516,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"4e56f06b-a914-426a-b1e9-9e4c28204152"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Step 3: Create Mappings for Words and Letters\n","\n","import os\n","\n","# Path to the dataset in Google Drive\n","dataset_path = '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS'  # Update this path if needed\n","\n","# Create mappings for words and letters\n","word_to_video = {}\n","letter_to_video = {}\n","\n","# Track words and letters that couldn't be mapped\n","missing_words = set()\n","\n","for root, dirs, files in os.walk(dataset_path):\n","    for file in files:\n","        if file.endswith('.mp4'):\n","            file_path = os.path.join(root, file)\n","            file_name = os.path.splitext(file)[0].strip()  # Strip extra spaces\n","\n","            # Debug print to verify filenames\n","            print(f\"Processing file: {file_name}\")\n","\n","            # Normalize filename to lowercase for consistent comparison\n","            normalized_file_name = file_name.lower()\n","\n","            # Assume file names for words are like 'hello.mp4' and for letters 'a.mp4', 'b.mp4', etc.\n","            if len(normalized_file_name) == 1 and normalized_file_name.isalpha():  # It's a letter\n","                letter_to_video[normalized_file_name] = file_path\n","            else:  # It's a word\n","                word_to_video[normalized_file_name] = file_path\n","\n","# Display mappings for verification\n","print(\"Word to Video Mapping (Sample):\", dict(list(word_to_video.items())[:10]))\n","print(\"Letter to Video Mapping (Sample):\", dict(list(letter_to_video.items())[:10]))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlJtYrmnm-no","executionInfo":{"status":"ok","timestamp":1722536467202,"user_tz":-330,"elapsed":1094,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"02a43db8-3e75-401c-caec-74c8a883e7ec"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing file: 0\n","Processing file: 1\n","Processing file: God\n","Processing file: 9\n","Processing file: Against\n","Processing file: Before\n","Processing file: From\n","Processing file: A\n","Processing file: Glitter\n","Processing file: Alone\n","Processing file: But\n","Processing file: And\n","Processing file: Change\n","Processing file: 6\n","Processing file: Go\n","Processing file: C\n","Processing file: 5\n","Processing file: 7\n","Processing file: Help\n","Processing file: Does Not\n","Processing file: Can\n","Processing file: Ask\n","Processing file: Better\n","Processing file: Best\n","Processing file: Engineer\n","Processing file: Day\n","Processing file: Cannot\n","Processing file: After\n","Processing file: Eat\n","Processing file: Beautiful\n","Processing file: 2\n","Processing file: Fight\n","Processing file: Happy\n","Processing file: Also\n","Processing file: Hands\n","Processing file: Her\n","Processing file: Finish\n","Processing file: Here\n","Processing file: Busy\n","Processing file: Hand\n","Processing file: D\n","Processing file: At\n","Processing file: Computer\n","Processing file: Do Not\n","Processing file: Come\n","Processing file: B\n","Processing file: Gold\n","Processing file: Do\n","Processing file: 8\n","Processing file: Bye\n","Processing file: Distance\n","Processing file: Again\n","Processing file: Great\n","Processing file: F\n","Processing file: G\n","Processing file: His\n","Processing file: H\n","Processing file: 3\n","Processing file: Be\n","Processing file: Good\n","Processing file: E\n","Processing file: Hello\n","Processing file: Age\n","Processing file: All\n","Processing file: College\n","Processing file: 4\n","Processing file: Walk\n","Processing file: ME\n","Processing file: More\n","Processing file: Our\n","Processing file: Talk\n","Processing file: U\n","Processing file: T\n","Processing file: Now\n","Processing file: J\n","Processing file: Keep\n","Processing file: We\n","Processing file: I\n","Processing file: When\n","Processing file: Out\n","Processing file: Learn\n","Processing file: Thank\n","Processing file: It\n","Processing file: L\n","Processing file: Study\n","Processing file: How\n","Processing file: R\n","Processing file: To\n","Processing file: Not\n","Processing file: Q\n","Processing file: Sad\n","Processing file: What\n","Processing file: Television\n","Processing file: Those\n","Processing file: Homepage\n","Processing file: My\n","Processing file: Next\n","Processing file: M\n","Processing file: Sign\n","Processing file: W\n","Processing file: N\n","Processing file: Of\n","Processing file: That\n","Processing file: Safe\n","Processing file: Time\n","Processing file: O\n","Processing file: Type\n","Processing file: Wash\n","Processing file: This\n","Processing file: Pretty\n","Processing file: V\n","Processing file: K\n","Processing file: S\n","Processing file: Us\n","Processing file: See\n","Processing file: On\n","Processing file: P\n","Processing file: Stay\n","Processing file: Self\n","Processing file: Name\n","Processing file: Sound\n","Processing file: Laugh\n","Processing file: Right\n","Processing file: Welcome\n","Processing file: Way\n","Processing file: Home\n","Processing file: Thank You\n","Processing file: Sing\n","Processing file: They\n","Processing file: So\n","Processing file: Invent\n","Processing file: Language\n","Processing file: X\n","Processing file: With\n","Processing file: Where\n","Processing file: Whole\n","Processing file: World\n","Processing file: You\n","Processing file: Who\n","Processing file: Yourself\n","Processing file: Words\n","Processing file: Z\n","Processing file: Will\n","Processing file: Y\n","Processing file: Your\n","Processing file: Work\n","Processing file: Which\n","Processing file: Without\n","Processing file: Why\n","Processing file: Whose\n","Processing file: Wrong\n","Word to Video Mapping (Sample): {'0': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/0.mp4', '1': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/1.mp4', 'god': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/God.mp4', '9': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/9.mp4', 'against': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Against.mp4', 'before': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Before.mp4', 'from': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/From.mp4', 'glitter': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Glitter.mp4', 'alone': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/Alone.mp4', 'but': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/But.mp4'}\n","Letter to Video Mapping (Sample): {'a': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/A.mp4', 'c': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/C.mp4', 'd': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/D.mp4', 'b': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/B.mp4', 'f': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/F.mp4', 'g': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/G.mp4', 'h': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/H.mp4', 'e': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/E.mp4', 'u': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/U.mp4', 't': '/content/drive/My Drive/speech/INDIAN SIGN LANGUAGE ANIMATED VIDEOS/T.mp4'}\n"]}]},{"cell_type":"code","source":["\n","# Step 4: Transcribe Audio to Text using Whisper\n","from google.colab import files\n","import whisper\n","from pydub import AudioSegment\n","import os\n","\n","# Load the pre-trained Whisper model\n","model = whisper.load_model(\"large\")\n","\n","def convert_to_wav(input_file):\n","    file_extension = os.path.splitext(input_file)[1].lower()\n","    if file_extension in ['.mp3', '.mp4']:\n","        audio = AudioSegment.from_file(input_file)\n","        wav_file = \"converted_audio.wav\"\n","        audio.export(wav_file, format=\"wav\")\n","        return wav_file\n","    elif file_extension == '.wav':\n","        return input_file\n","    else:\n","        raise ValueError(f\"Unsupported file format: {file_extension}\")\n","\n","def audio_to_text(audio_file_path):\n","    wav_file = convert_to_wav(audio_file_path)\n","    result = model.transcribe(wav_file)\n","    return result[\"text\"]\n","\n","# Prompt user to upload an audio file\n","print(\"Please upload your audio file.\")\n","uploaded = files.upload()\n","\n","# Get the name of the uploaded file\n","audio_file_path = list(uploaded.keys())[0]\n","transcribed_text = audio_to_text(audio_file_path)\n","print(\"Transcribed Text:\", transcribed_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":160},"id":"MnkR1vuonDAx","executionInfo":{"status":"ok","timestamp":1722536748442,"user_tz":-330,"elapsed":263541,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"e03fb510-46e1-4517-8fdb-5f14118662b5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████████████████████████████████| 2.88G/2.88G [00:30<00:00, 102MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Please upload your audio file.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d37f6127-aeb5-45c9-9761-9c66e84b3f24\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d37f6127-aeb5-45c9-9761-9c66e84b3f24\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving h-ap kaise ho.mp3 to h-ap kaise ho.mp3\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"]},{"output_type":"stream","name":"stdout","text":["Transcribed Text:  आप कैसे हो?\n"]}]},{"cell_type":"code","source":["# Translate to english language\n","\n","!pip install deep-translator\n","\n","\n","from deep_translator import GoogleTranslator\n","\n","text = transcribed_text\n","translator = GoogleTranslator(source='auto', target='en')\n","translated_text = translator.translate(text)\n","print(translated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wR1mxGG9Mr6d","executionInfo":{"status":"ok","timestamp":1722537011254,"user_tz":-330,"elapsed":3634,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"48778a04-bab3-4a61-8574-ad9863578aab"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deep-translator in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.7.4)\n","How are you?\n"]}]},{"cell_type":"code","source":["\n","# Step 5: Generate the ISL Video\n","\n","from moviepy.editor import VideoFileClip, concatenate_videoclips\n","import re\n","\n","def clean_text(text):\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove any non-alphanumeric characters except spaces\n","    text = re.sub(r'[^a-z0-9\\s]', '', text)\n","    return text\n","\n","from moviepy.editor import VideoFileClip, concatenate_videoclips\n","\n","def generate_isl_video(input_text, word_to_video, letter_to_video):\n","    video_clips = []\n","    words = clean_text(input_text).split()\n","\n","    for word in words:\n","        if word in word_to_video:\n","            video_path = word_to_video[word]\n","            clip = VideoFileClip(video_path)\n","            video_clips.append(clip)\n","        else:\n","            print(f\"No video found for word: {word}. Spelling out the word.\")\n","            for letter in word:\n","                if letter in letter_to_video:\n","                    video_path = letter_to_video[letter]\n","                    clip = VideoFileClip(video_path)\n","                    video_clips.append(clip)\n","                else:\n","                    print(f\"No video found for letter: {letter}\")\n","\n","    if video_clips:\n","        final_video = concatenate_videoclips(video_clips, method=\"compose\")\n","        final_video.write_videofile(\"l_output_video.mp4\")\n","    else:\n","        print(\"No valid ISL videos found for the given text.\")\n","\n","# Generate the ISL video using the transcribed text\n","generate_isl_video(translated_text, word_to_video, letter_to_video)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LwMoEgCynGnd","executionInfo":{"status":"ok","timestamp":1722537268251,"user_tz":-330,"elapsed":9668,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"52c69729-086e-42c8-c296-6af426ea0730"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["No video found for word: are. Spelling out the word.\n","Moviepy - Building video l_output_video.mp4.\n","Moviepy - Writing video l_output_video.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready l_output_video.mp4\n"]}]},{"cell_type":"code","source":["\n","from google.colab import files\n","\n","# Download the video\n","files.download(\"l_output_video.mp4\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"39Hb3T-3nLE0","executionInfo":{"status":"ok","timestamp":1722537274679,"user_tz":-330,"elapsed":397,"user":{"displayName":"BANDHICHODU VENKATA VENKAT","userId":"03166832433133209739"}},"outputId":"b4c2de6d-3f0c-4ae5-bf92-3a2dba968fc9"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_5cfd4303-9cd0-49c4-a31c-e949943334c8\", \"l_output_video.mp4\", 173476)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"kl3xzAyqq-dE"},"execution_count":null,"outputs":[]}]}